{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Main Network Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohit901/ForeheadCreases/blob/main/Main_Network_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80mPHdATEtti"
      },
      "source": [
        "from torch.nn import AdaptiveMaxPool2d, \\\n",
        "    NLLLoss, BCELoss, CrossEntropyLoss, Softmax, Embedding\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import optim\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import time\n",
        "from torchsummary import summary\n",
        "import os\n",
        "from easydict import EasyDict as edict\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms as trans\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import  DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "#from tensorboardX import SummaryWriter\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import roc_curve\n",
        "import numpy as np\n",
        "from torch.nn import init\n",
        "from collections import namedtuple\n",
        "from torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, PReLU, ReLU, Sigmoid, Dropout2d, Dropout, AvgPool2d, MaxPool2d, AdaptiveAvgPool2d, Sequential, Parameter, Module, CrossEntropyLoss, DataParallel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mio6BLLYddsK"
      },
      "source": [
        "#### Image Width, Image Height was set to 224 in this work.\n",
        "#### RGB Images of Forehead ROI have been used.\n",
        "#### Embedding Dimension is set to 512.\n",
        "## Do Not Modify or delete the below code cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfni0BECEttm"
      },
      "source": [
        "img_width = 224\n",
        "img_height = 224\n",
        "channels = 3\n",
        "embedding_dim = 512\n",
        "\n",
        "size1_new = int(np.floor(img_width/2))\n",
        "size2_new = int(np.floor(img_height/2))\n",
        "\n",
        "size1_new = int(np.ceil(size1_new/2))\n",
        "size2_new = int(np.ceil(size2_new/2))\n",
        "\n",
        "size1_new = int(np.ceil(size1_new/2))\n",
        "size2_new = int(np.ceil(size2_new/2))\n",
        "\n",
        "size1_new = int(np.ceil(size1_new/2))\n",
        "size2_new = int(np.ceil(size2_new/2))\n",
        "\n",
        "size1_new = int(np.floor(size1_new/2))\n",
        "size2_new = int(np.floor(size2_new/2))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51XPq-xtEttn"
      },
      "source": [
        "def get_train_dataset(imgs_folder):\n",
        "    if channels != 3:\n",
        "        train_transform = trans.Compose([\n",
        "            trans.Grayscale(num_output_channels=channels), \n",
        "            trans.Resize((img_width, img_height)), \n",
        "            trans.RandomHorizontalFlip(),\n",
        "            trans.ToTensor(),\n",
        "            trans.Normalize((0.5,), (0.5,))\n",
        "            \n",
        "        ])\n",
        "    else:\n",
        "        train_transform = trans.Compose([\n",
        "            trans.Resize((img_width, img_height)), \n",
        "            trans.RandomHorizontalFlip(),\n",
        "            trans.ToTensor(),\n",
        "            trans.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "    ds = ImageFolder(imgs_folder, train_transform)\n",
        "    class_num = ds[-1][1] + 1\n",
        "    return ds, class_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyRnyz5eEtto"
      },
      "source": [
        "### Code for ArcFace and CosFace has been obtained from the following repository: https://github.com/ronghuaiyang/arcface-pytorch/blob/master/models/metrics.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY7DbddcEttp"
      },
      "source": [
        "class FocalLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, gamma=0, eps=1e-7):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.eps = eps\n",
        "        self.ce = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        logp = self.ce(input, target)\n",
        "        p = torch.exp(-logp)\n",
        "        loss = (1 - p) ** self.gamma * logp\n",
        "        return loss.mean()\n",
        "\n",
        "\n",
        "class ArcMarginProduct(nn.Module):\n",
        "    r\"\"\"Implement of large margin arc distance: :\n",
        "        Args:\n",
        "            in_features: size of each input sample\n",
        "            out_features: size of each output sample\n",
        "            s: norm of input feature\n",
        "            m: margin\n",
        "\n",
        "            cos(theta + m)\n",
        "        \"\"\"\n",
        "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False):\n",
        "        super(ArcMarginProduct, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = math.cos(m)\n",
        "        self.sin_m = math.sin(m)\n",
        "        self.th = math.cos(math.pi - m)\n",
        "        self.mm = math.sin(math.pi - m) * m\n",
        "\n",
        "    def forward(self, input, label):\n",
        "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
        "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
        "        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = torch.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        # --------------------------- convert label to one-hot ---------------------------\n",
        "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
        "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
        "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
        "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n",
        "        output *= self.s\n",
        "        # print(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class AddMarginProduct(nn.Module):\n",
        "    r\"\"\"Implement of large margin cosine distance: :\n",
        "    Args:\n",
        "        in_features: size of each input sample\n",
        "        out_features: size of each output sample\n",
        "        s: norm of input feature\n",
        "        m: margin\n",
        "        cos(theta) - m\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, s=30.0, m=0.40):\n",
        "        super(AddMarginProduct, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "    def forward(self, input, label):\n",
        "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
        "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
        "        phi = cosine - self.m\n",
        "        # --------------------------- convert label to one-hot ---------------------------\n",
        "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
        "        # one_hot = one_hot.cuda() if cosine.is_cuda else one_hot\n",
        "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
        "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n",
        "        output *= self.s\n",
        "        # print(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' \\\n",
        "               + 'in_features=' + str(self.in_features) \\\n",
        "               + ', out_features=' + str(self.out_features) \\\n",
        "               + ', s=' + str(self.s) \\\n",
        "               + ', m=' + str(self.m) + ')'\n",
        "\n",
        "\n",
        "class SphereProduct(nn.Module):\n",
        "    r\"\"\"Implement of large margin cosine distance: :\n",
        "    Args:\n",
        "        in_features: size of each input sample\n",
        "        out_features: size of each output sample\n",
        "        m: margin\n",
        "        cos(m*theta)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features, m=4):\n",
        "        super(SphereProduct, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.m = m\n",
        "        self.base = 1000.0\n",
        "        self.gamma = 0.12\n",
        "        self.power = 1\n",
        "        self.LambdaMin = 5.0\n",
        "        self.iter = 0\n",
        "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
        "        nn.init.xavier_uniform(self.weight)\n",
        "\n",
        "        # duplication formula\n",
        "        self.mlambda = [\n",
        "            lambda x: x ** 0,\n",
        "            lambda x: x ** 1,\n",
        "            lambda x: 2 * x ** 2 - 1,\n",
        "            lambda x: 4 * x ** 3 - 3 * x,\n",
        "            lambda x: 8 * x ** 4 - 8 * x ** 2 + 1,\n",
        "            lambda x: 16 * x ** 5 - 20 * x ** 3 + 5 * x\n",
        "        ]\n",
        "\n",
        "    def forward(self, input, label):\n",
        "        # lambda = max(lambda_min,base*(1+gamma*iteration)^(-power))\n",
        "        self.iter += 1\n",
        "        self.lamb = max(self.LambdaMin, self.base * (1 + self.gamma * self.iter) ** (-1 * self.power))\n",
        "\n",
        "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
        "        cos_theta = F.linear(F.normalize(input), F.normalize(self.weight))\n",
        "        cos_theta = cos_theta.clamp(-1, 1)\n",
        "        cos_m_theta = self.mlambda[self.m](cos_theta)\n",
        "        theta = cos_theta.data.acos()\n",
        "        k = (self.m * theta / 3.14159265).floor()\n",
        "        phi_theta = ((-1.0) ** k) * cos_m_theta - 2 * k\n",
        "        NormOfFeature = torch.norm(input, 2, 1)\n",
        "\n",
        "        # --------------------------- convert label to one-hot ---------------------------\n",
        "        one_hot = torch.zeros(cos_theta.size())\n",
        "        one_hot = one_hot.cuda() if cos_theta.is_cuda else one_hot\n",
        "        one_hot.scatter_(1, label.view(-1, 1), 1)\n",
        "\n",
        "        # --------------------------- Calculate output ---------------------------\n",
        "        output = (one_hot * (phi_theta - cos_theta) / (1 + self.lamb)) + cos_theta\n",
        "        output *= NormOfFeature.view(-1, 1)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' \\\n",
        "               + 'in_features=' + str(self.in_features) \\\n",
        "               + ', out_features=' + str(self.out_features) \\\n",
        "               + ', m=' + str(self.m) + ')'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-ecjQ-AfKsW"
      },
      "source": [
        "### Code for Attention Modules have been obtained from: https://github.com/xmu-xiaoma666/External-Attention-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knbtK9hh9Kif"
      },
      "source": [
        "class PAM_Module(nn.Module):\n",
        "    \"\"\" Position attention module\"\"\"\n",
        "    #Ref from SAGAN\n",
        "    def __init__(self, in_dim = 512):\n",
        "        super(PAM_Module, self).__init__()\n",
        "        self.chanel_in = in_dim\n",
        "\n",
        "        self.query_conv = Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
        "        self.key_conv = Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
        "        self.value_conv = Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
        "        self.gamma = Parameter(torch.zeros(1))\n",
        "\n",
        "        self.softmax = Softmax(dim=-1)\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "            inputs :\n",
        "                x : input feature maps( B X C X H X W)\n",
        "            returns :\n",
        "                out : attention value + input feature\n",
        "                attention: B X (HxW) X (HxW)\n",
        "        \"\"\"\n",
        "        m_batchsize, C, height, width = x.size()\n",
        "        proj_query = self.query_conv(x).view(m_batchsize, -1, width*height).permute(0, 2, 1)\n",
        "        proj_key = self.key_conv(x).view(m_batchsize, -1, width*height)\n",
        "        energy = torch.bmm(proj_query, proj_key)\n",
        "        attention = self.softmax(energy)\n",
        "        proj_value = self.value_conv(x).view(m_batchsize, -1, width*height)\n",
        "\n",
        "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
        "        out = out.view(m_batchsize, C, height, width)\n",
        "\n",
        "        #out = self.gamma*out\n",
        "        out = self.gamma*out + x\n",
        "        return out\n",
        "\n",
        "class ECAAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, kernel_size=5):\n",
        "        super().__init__()\n",
        "        self.gap=nn.AdaptiveAvgPool2d(1)\n",
        "        self.conv=nn.Conv1d(1,1,kernel_size=kernel_size,padding=(kernel_size-1)//2)\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                init.constant_(m.weight, 1)\n",
        "                init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                init.normal_(m.weight, std=0.001)\n",
        "                if m.bias is not None:\n",
        "                    init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y=self.gap(x) #bs,c,1,1\n",
        "        y=y.squeeze(-1).permute(0,2,1) #bs,1,c\n",
        "        y=self.conv(y) #bs,1,c\n",
        "        y=self.sigmoid(y) #bs,1,c\n",
        "        y=y.permute(0,2,1).unsqueeze(-1) #bs,c,1,1\n",
        "        return x*y.expand_as(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FErDkMoJEttu"
      },
      "source": [
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class IRBlock(nn.Module): \n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_se=True):\n",
        "        super(IRBlock, self).__init__()\n",
        "        self.bn0 = nn.BatchNorm2d(inplanes)\n",
        "        self.conv1 = conv3x3(inplanes, inplanes)\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.conv2 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.use_se = use_se\n",
        "        if self.use_se:\n",
        "            self.se = SEBlock(planes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.bn0(x)\n",
        "        out = self.conv1(out)\n",
        "        out = self.bn1(out)\n",
        "        out = self.prelu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.use_se:\n",
        "            out = self.se(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.prelu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "                nn.Linear(channel, channel // reduction),\n",
        "                nn.PReLU(),\n",
        "                nn.Linear(channel // reduction, channel),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "class ResNetFace(nn.Module):\n",
        "    def __init__(self, block, layers, use_se=True):\n",
        "        self.inplanes = 64\n",
        "        self.use_se = use_se\n",
        "        super(ResNetFace, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, 64, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.sattention = PAM_Module()\n",
        "        self.cattention = ECAAttention(kernel_size = 5)\n",
        "        \n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        self.dropout = nn.Dropout()\n",
        "        \n",
        "        self.fc5 = nn.Linear(512 * (size1_new) * (size2_new), embedding_dim)\n",
        "        self.bn5 = nn.BatchNorm1d(embedding_dim)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, use_se=self.use_se))\n",
        "        self.inplanes = planes\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, use_se=self.use_se))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.prelu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.maxpool(x)\n",
        "        \n",
        "        \n",
        "        s_x = self.sattention(x) #spatial or positional attention.\n",
        "        c_x = self.cattention(x)\n",
        "        \n",
        "        x = c_x + s_x #Element Sum Concat of Attention Outputs.\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc5(x)\n",
        "        x = self.bn5(x)\n",
        "        return x\n",
        "\n",
        "def resnet_18(use_se=True, **kwargs):\n",
        "    model = ResNetFace(IRBlock, [2, 2, 2, 2], use_se=use_se, **kwargs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWo0p9pSuevH"
      },
      "source": [
        "# Load The Dataset. Replace below lines accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irc5wuO0GWoN"
      },
      "source": [
        "ds, class_num = get_train_dataset(\"dataset/train\")\n",
        "ds2, class_num2 = get_train_dataset(\"dataset/test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VksS53e929k"
      },
      "source": [
        "### Configuration Settings for the Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BG5ngBxEtt1"
      },
      "source": [
        "class Config(object):\n",
        "    env = 'default'\n",
        "    backbone = 'resnet18'\n",
        "    classify = 'softmax'\n",
        "    num_classes = class_num\n",
        "    metric = 'add_margin' #add_margin for CosFace and arc_margin for ArcFace loss.\n",
        "    easy_margin = False\n",
        "    use_se = False\n",
        "    #loss = \"cross_entropy\"\n",
        "    loss = 'focal_loss'\n",
        "\n",
        "    pin_memory = True\n",
        "    \n",
        "    display = True\n",
        "    finetune = False\n",
        "\n",
        "    checkpoints_path = 'checkpoints' #folder name where the checkpoints will be stored.\n",
        "    load_model_path = 'models/resnet18.pth'\n",
        "    test_model_path = 'checkpoints/resnet18_110.pth'\n",
        "    save_interval = 100\n",
        "\n",
        "    train_batch_size = 16  # batch size\n",
        "    test_batch_size = 32\n",
        "\n",
        "    input_shape = (channels, img_width, img_height)\n",
        "\n",
        "    optimizer = 'adam'\n",
        "\n",
        "    use_gpu = True  # use GPU or not\n",
        "    gpu_id = '0, 1'\n",
        "    num_workers = 2  # how many workers for loading data\n",
        "    print_freq = 100  # print info every N batch\n",
        "\n",
        "    debug_file = '/tmp/debug'  # if os.path.exists(debug_file): enter ipdb\n",
        "    result_file = 'result.csv'\n",
        "\n",
        "    \n",
        "    max_epoch = 100\n",
        "    lr = 3e-4  # initial learning rate before 1e-3\n",
        "    lr_step = 20\n",
        "    lr_decay = 0.95  # when val_loss increase, lr = lr*lr_decay\n",
        "    weight_decay = 5e-4\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrF5VLTNEtt1"
      },
      "source": [
        "opt = Config()\n",
        "loader = DataLoader(ds, batch_size= opt.train_batch_size, shuffle=True, pin_memory= opt.pin_memory, num_workers= opt.num_workers)\n",
        "test_loader = DataLoader(ds2, batch_size = opt.test_batch_size)\n",
        "class_names = ds.classes\n",
        "\n",
        "device = torch.device(\"cuda\") # Train on GPU.\n",
        "if opt.loss == 'focal_loss':\n",
        "    criterion = FocalLoss(gamma=2)\n",
        "else:\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "model = resnet_18(use_se=opt.use_se)\n",
        "\n",
        "\n",
        "if opt.metric == 'add_margin':\n",
        "    metric_fc = AddMarginProduct(embedding_dim, opt.num_classes, s=300, m=0.35)\n",
        "elif opt.metric == 'arc_margin':\n",
        "    metric_fc = ArcMarginProduct(embedding_dim, opt.num_classes, s=300, m=0.35, easy_margin=opt.easy_margin)\n",
        "elif opt.metric == 'sphere':\n",
        "    metric_fc = SphereProduct(embedding_dim, opt.num_classes, m=4)\n",
        "else:\n",
        "    metric_fc = nn.Linear(embedding_dim, opt.num_classes)\n",
        "\n",
        "model.to(device)\n",
        "model = DataParallel(model)\n",
        "metric_fc.to(device)\n",
        "metric_fc = DataParallel(metric_fc)\n",
        "if opt.optimizer == 'sgd':\n",
        "    optimizer = torch.optim.SGD([{'params': model.parameters()}, {'params': metric_fc.parameters()}],\n",
        "                                lr=opt.lr, weight_decay=opt.weight_decay)\n",
        "else:\n",
        "    optimizer = torch.optim.Adam([{'params': model.parameters()}, {'params': metric_fc.parameters()}],\n",
        "                                 lr=opt.lr, weight_decay=opt.weight_decay)\n",
        "scheduler = StepLR(optimizer, step_size=opt.lr_step, gamma=0.1) #decays learning rate by gamma every step_size epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGRRJ0m9Ett7"
      },
      "source": [
        "def save_model(model, save_path, name, iter_cnt):\n",
        "    save_name = os.path.join(save_path, name + '_' + str(iter_cnt) + '.pth')\n",
        "    torch.save(model.state_dict(), save_name)\n",
        "    return save_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLb0X_vB_2Pn"
      },
      "source": [
        "# Do Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxsr-HsyEtt-",
        "scrolled": false
      },
      "source": [
        "val_acc = []\n",
        "train_acc = []\n",
        "loss_list = []\n",
        "for i in range(opt.max_epoch):\n",
        "    \n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "    for ii, data in enumerate(loader):\n",
        "        data_input, label = data\n",
        "        data_input = data_input.to(device)\n",
        "        bs = data_input.shape[0]\n",
        "        label = label.to(device).long()\n",
        "        feature = model(data_input)\n",
        "        output = metric_fc(feature, label)\n",
        "        loss = criterion(output, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += (bs * loss.item())\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = output.data.cpu().numpy()\n",
        "            output = np.argmax(output, axis = 1)\n",
        "            label = label.data.cpu().numpy()\n",
        "            \n",
        "            total_train += label.shape[0]\n",
        "            correct_train += (output == label).sum().item()\n",
        "            \n",
        "\n",
        "    if i % opt.save_interval == 0 or i == opt.max_epoch:\n",
        "        save_model(model, opt.checkpoints_path, \"Model_Weights\", i)\n",
        "        \n",
        "    model.eval()\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for vdata in test_loader:\n",
        "            vimage, vlabel = vdata[0].to(device), vdata[1].to(device).long()\n",
        "            val_feature = model(vimage)\n",
        "            val_output = metric_fc(val_feature, vlabel)\n",
        "            val_output = val_output.data.cpu().numpy()\n",
        "            val_output = np.argmax(val_output, axis = 1)\n",
        "            vlabel = vlabel.data.cpu().numpy()\n",
        "            total_val += vlabel.shape[0]\n",
        "            correct_val += (val_output == vlabel).sum().item()\n",
        "    val_acc.append(np.round(100 * correct_val / total_val,2))\n",
        "    train_acc.append(np.round(100 * correct_train / total_train,2))\n",
        "    print(f\"Epoch: {i+1}, Validation Accuracy: {np.round(100 * correct_val / total_val,2)}%, Training Accuracy: {np.round(100 * correct_train / total_train,2)}%, Loss: {np.round(running_loss / total_train,2)}\")\n",
        "    loss_list.append(np.round(running_loss / total_train,2) )\n",
        "    scheduler.step()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "\n",
        "plt.annotate(f'Maximum Accuracy\\n at ({np.argmax(train_acc)+1}, {int(max(train_acc))}) ', xy=(np.argmax(train_acc)+1, max(train_acc)), xytext=(np.argmax(train_acc)-10, max(train_acc)-25),\n",
        "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
        "             )\n",
        "plt.annotate(f'Accuracy\\n ({len(train_acc)}, {train_acc[-1]}) ', xy=(len(train_acc), train_acc[-1]), xytext=(len(train_acc)-10, train_acc[-1]-25),\n",
        "             arrowprops=dict(facecolor='blue', shrink=0.05),\n",
        "             )\n",
        "plt.plot(range(1,opt.max_epoch+1), train_acc)\n",
        "plt.savefig(\"train_accuracy.png\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.title(\"Testing Accuracy\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "\n",
        "plt.annotate(f'Maximum Accuracy\\n at ({np.argmax(val_acc)+1}, {max(val_acc)}) ', xy=(np.argmax(val_acc)+1, max(val_acc)), xytext=(np.argmax(val_acc)-4, max(val_acc)-10),\n",
        "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
        "             )\n",
        "plt.annotate(f'Accuracy\\n ({len(val_acc)}, {val_acc[-1]}) ', xy=(len(val_acc), val_acc[-1]), xytext=(len(val_acc)-10, val_acc[-1]-5),\n",
        "             arrowprops=dict(facecolor='blue', shrink=0.05),\n",
        "             )\n",
        "plt.plot(range(1,opt.max_epoch+1), val_acc)\n",
        "plt.savefig(\"test_accuracy.png\")\n",
        "\n",
        "\n",
        "plt.figure(figsize = (10,6))\n",
        "plt.title(\"loss Curve\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(range(1, opt.max_epoch+1), loss_list)\n",
        "plt.savefig(\"loss_curve.png\")\n",
        "\n",
        "\n",
        "import pickle\n",
        "with open(\"loss_data.pkl\", \"wb\") as file:\n",
        "  pickle.dump(loss_list, file)\n",
        "\n",
        "\n",
        "save_model(model, opt.checkpoints_path, \"Model_Weights\", 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U92iKGmxdRH"
      },
      "source": [
        "# Load Embeddings in Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUBlfU-AxU4a"
      },
      "source": [
        "class ImageFolderWithPaths(ImageFolder):\n",
        "    def __getitem__(self, index):\n",
        "        return super(ImageFolderWithPaths, self).__getitem__(index) + (self.imgs[index][0],)\n",
        "\n",
        "\n",
        "\n",
        "def get_dataset_modified(imgs_folder):\n",
        "    if channels != 3:\n",
        "        train_transform = trans.Compose([\n",
        "            trans.Grayscale(num_output_channels=channels),\n",
        "            trans.Resize((img_width, img_height)),\n",
        "            trans.RandomHorizontalFlip(),\n",
        "            trans.ToTensor(),\n",
        "            trans.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "    else:\n",
        "        train_transform = trans.Compose([\n",
        "            trans.Resize((img_width, img_height)),\n",
        "            trans.RandomHorizontalFlip(),\n",
        "            trans.ToTensor(),\n",
        "            trans.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "    ds = ImageFolderWithPaths(imgs_folder, train_transform)\n",
        "    class_num = ds[-2][1] + 1\n",
        "    return ds, class_num\n",
        "\n",
        "\n",
        "ds3, cnum = get_dataset_modified(\"dataset/test\")\n",
        "ds4, cnum2 = get_dataset_modified(\"dataset/train\")\n",
        "\n",
        "new_loader = DataLoader(ds3, batch_size = 1)\n",
        "new_loader_train = DataLoader(ds4, batch_size = 1)\n",
        "\n",
        "\n",
        "embedding_dict_test = {}\n",
        "embedding_dict_train = {}\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for i, data in enumerate(new_loader, 0):\n",
        "            images, labels, path = data\n",
        "            images = images.to(device)\n",
        "            feature_test = model(images) #512 dimensional embedding\n",
        "            idx1 = path[0].split(\"/\")[2] \n",
        "            pose1 = path[0].split(\"/\")[-1][:-4]\n",
        "            embedding_dict_test[str(idx1)+\"_\"+str(pose1)] = feature_test.cpu()\n",
        "\n",
        "    for i2, data_train in enumerate(new_loader_train):\n",
        "            images_train, labels_train, path_train = data_train\n",
        "            images_train = images_train.to(device)\n",
        "            feature_train = model(images_train)\n",
        "            idx2 = path_train[0].split(\"/\")[2] \n",
        "            pose2 = path_train[0].split(\"/\")[-1][:-4]\n",
        "            embedding_dict_train[str(idx2)+\"_\"+str(pose2)] = feature_train.cpu()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHmHQO-LyCby"
      },
      "source": [
        "#Create Matching Score File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3zly_NbyCD6"
      },
      "source": [
        "for k_test,v_test in embedding_dict_test.items():\n",
        "  myKList = k_test.split(\"_\")\n",
        "  idx1 = myKList[0]\n",
        "  pose1 = myKList[1]\n",
        "  for k_train,v_train in embedding_dict_train.items():\n",
        "    myKList2 = k_train.split(\"_\")\n",
        "    idx2 = myKList2[0]\n",
        "    pose2 = myKList2[1]\n",
        "    if idx1 == idx2:\n",
        "      isGen = 1\n",
        "    else:\n",
        "      isGen = 0\n",
        "    with open(\"scores.txt\", \"a\") as file:\n",
        "      file.write(str(idx1) + \"\\t\" + str(pose1) + \"\\t\" + str(idx2) + \"\\t\" + str(pose2) + \"\\t\" + str(isGen) + \"\\t\" + str(torch.dist(v_test, v_train, p = 2).item()) + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEOjL6rJykm7"
      },
      "source": [
        "# Once the Score file is created, you can compute standard biometric results like CRR, EER, DI, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8hOjdoxyvQx"
      },
      "source": [
        "# Android and Network Code written by Rohit K Bharadwaj.\n",
        "## Follow me on:\n",
        "### Twitter: https://twitter.com/rohit901\n",
        "### Github: https://github.com/rohit901\n",
        "### LinkedIn: https://www.linkedin.com/in/rohit901/\n",
        "\n"
      ]
    }
  ]
}